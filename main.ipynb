{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2487d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deeecb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadCSV(dir_path: str):\n",
    "    \"\"\"\n",
    "    讀取交易資料與警示帳戶註記\n",
    "    \"\"\"\n",
    "    df_txn = pd.read_csv(os.path.join(dir_path, \"filtered_output.csv\"))\n",
    "    df_alert = pd.read_csv(os.path.join(dir_path, \"acct_alert.csv\"))\n",
    "\n",
    "    print(\"(Finish) Load Dataset.\")\n",
    "    return df_txn, df_alert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "241b1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcessing(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    為每個帳戶做特徵工程：\n",
    "    1. 金額統計：total / max / min / avg (send/recv)\n",
    "    2. 交易筆數：send_cnt / recv_cnt\n",
    "    3. unique 對手帳戶數：unique_to_cnt / unique_from_cnt\n",
    "    4. 衍生旗標：only_send / only_recv\n",
    "    5. 比例類特徵：avg_per_txn, flow_ratio, cnt_ratio\n",
    "    6. is_esun (是否玉山帳戶)\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- 1. 基本金額統計 ----\n",
    "    send = df.groupby(\"from_acct\")[\"txn_amt\"].sum().rename(\"total_send_amt\")\n",
    "    recv = df.groupby(\"to_acct\")[\"txn_amt\"].sum().rename(\"total_recv_amt\")\n",
    "\n",
    "    max_send = df.groupby(\"from_acct\")[\"txn_amt\"].max().rename(\"max_send_amt\")\n",
    "    min_send = df.groupby(\"from_acct\")[\"txn_amt\"].min().rename(\"min_send_amt\")\n",
    "    avg_send = df.groupby(\"from_acct\")[\"txn_amt\"].mean().rename(\"avg_send_amt\")\n",
    "\n",
    "    max_recv = df.groupby(\"to_acct\")[\"txn_amt\"].max().rename(\"max_recv_amt\")\n",
    "    min_recv = df.groupby(\"to_acct\")[\"txn_amt\"].min().rename(\"min_recv_amt\")\n",
    "    avg_recv = df.groupby(\"to_acct\")[\"txn_amt\"].mean().rename(\"avg_recv_amt\")\n",
    "\n",
    "    # ---- 2. 交易筆數 (degree-ish) ----\n",
    "    send_cnt = df.groupby(\"from_acct\").size().rename(\"send_cnt\")\n",
    "    recv_cnt = df.groupby(\"to_acct\").size().rename(\"recv_cnt\")\n",
    "\n",
    "    # ---- 3. unique 對手帳戶數（graph 特徵的入門版） ----\n",
    "    # from_acct 對多少不同 to_acct 匯款\n",
    "    unique_to_cnt = (\n",
    "        df.groupby(\"from_acct\")[\"to_acct\"]\n",
    "        .nunique()\n",
    "        .rename(\"unique_to_cnt\")\n",
    "    )\n",
    "    # to_acct 從多少不同 from_acct 收款\n",
    "    unique_from_cnt = (\n",
    "        df.groupby(\"to_acct\")[\"from_acct\"]\n",
    "        .nunique()\n",
    "        .rename(\"unique_from_cnt\")\n",
    "    )\n",
    "\n",
    "    # ---- 4. 合併帳戶層級特徵 ----\n",
    "    df_result = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                max_send,\n",
    "                min_send,\n",
    "                avg_send,\n",
    "                max_recv,\n",
    "                min_recv,\n",
    "                avg_recv,\n",
    "                send,\n",
    "                recv,\n",
    "                send_cnt,\n",
    "                recv_cnt,\n",
    "                unique_to_cnt,\n",
    "                unique_from_cnt,\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        .fillna(0)\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_result.rename(columns={\"index\": \"acct\"}, inplace=True)\n",
    "\n",
    "    # ---- 5. 是否玉山帳戶 is_esun ----\n",
    "    df_from = df[[\"from_acct\", \"from_acct_type\"]].rename(\n",
    "        columns={\"from_acct\": \"acct\", \"from_acct_type\": \"is_esun\"}\n",
    "    )\n",
    "    df_to = df[[\"to_acct\", \"to_acct_type\"]].rename(\n",
    "        columns={\"to_acct\": \"acct\", \"to_acct_type\": \"is_esun\"}\n",
    "    )\n",
    "    df_acc = (\n",
    "        pd.concat([df_from, df_to], ignore_index=True)\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    df_result = pd.merge(df_result, df_acc, on=\"acct\", how=\"left\")\n",
    "    df_result[\"is_esun\"] = df_result[\"is_esun\"].fillna(0).astype(int)\n",
    "\n",
    "    # ---- 6. 衍生特徵 ----\n",
    "    # 避免除以 0，加 1\n",
    "    df_result[\"avg_send_per_txn\"] = df_result[\"total_send_amt\"] / (\n",
    "        df_result[\"send_cnt\"] + 1\n",
    "    )\n",
    "    df_result[\"avg_recv_per_txn\"] = df_result[\"total_recv_amt\"] / (\n",
    "        df_result[\"recv_cnt\"] + 1\n",
    "    )\n",
    "\n",
    "    # 收入 / 支出 金額比例\n",
    "    df_result[\"flow_ratio\"] = (df_result[\"total_recv_amt\"] + 1) / (\n",
    "        df_result[\"total_send_amt\"] + 1\n",
    "    )\n",
    "\n",
    "    # 出 / 入 筆數比例\n",
    "    df_result[\"cnt_ratio\"] = (df_result[\"send_cnt\"] + 1) / (\n",
    "        df_result[\"recv_cnt\"] + 1\n",
    "    )\n",
    "\n",
    "    # 是否只收不付、只付不收\n",
    "    df_result[\"only_recv\"] = (df_result[\"send_cnt\"] == 0).astype(int)\n",
    "    df_result[\"only_send\"] = (df_result[\"recv_cnt\"] == 0).astype(int)\n",
    "\n",
    "    # 總共接觸過多少不同 counterparty\n",
    "    df_result[\"neighbor_cnt\"] = (\n",
    "        df_result[\"unique_to_cnt\"] + df_result[\"unique_from_cnt\"]\n",
    "    )\n",
    "\n",
    "    print(\"(Finish) PreProcessing.\")\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1eee661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainTestSplit(df_X: pd.DataFrame, df_alert: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    1. 用 acct_alert 標記 label (0/1)\n",
    "    2. 僅使用 is_esun == 1 的帳戶\n",
    "    3. stratified train/test split\n",
    "    \"\"\"\n",
    "    df = df_X.copy()\n",
    "    df[\"label\"] = df[\"acct\"].isin(df_alert[\"acct\"]).astype(int)\n",
    "\n",
    "    # 僅玉山戶（符合比賽設定）\n",
    "    df = df[df[\"is_esun\"] == 1].reset_index(drop=True)\n",
    "\n",
    "    pos = df[\"label\"].sum()\n",
    "    neg = len(df) - pos\n",
    "    print(\n",
    "        f\"Total accounts (esun only): {len(df)}, \"\n",
    "        f\"positives={pos}, negatives={neg}, ratio={pos/(pos+neg+1e-9):.6f}\"\n",
    "    )\n",
    "\n",
    "    train_df, test_df = train_test_split(\n",
    "        df,\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=df[\"label\"],\n",
    "    )\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"label\"])\n",
    "    y_train = train_df[\"label\"]\n",
    "\n",
    "    X_test = test_df.drop(columns=[\"label\"])\n",
    "    y_test = test_df[\"label\"]\n",
    "\n",
    "    print(\n",
    "        f\"(Finish) Train-Test Split. \"\n",
    "        f\"Train={len(X_train)}, Test={len(X_test)}\"\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "586c173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_Modeling(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    RandomForest + validation threshold tuning:\n",
    "    1. 從 training set 再切出 validation\n",
    "    2. 在 validation 上掃描 threshold，找 F1 最高\n",
    "    3. 用整個 training 重練，再在 test 上用該 threshold\n",
    "    \"\"\"\n",
    "\n",
    "    feature_cols = [c for c in X_train.columns if c not in [\"acct\"]]\n",
    "\n",
    "    # train / val split\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train[feature_cols],\n",
    "        y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_train,\n",
    "    )\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "    )\n",
    "\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    # validation 上掃 threshold\n",
    "    val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    best_t = 0.5\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    for t in np.linspace(0.05, 0.95, 19):  # 0.05, 0.10, ..., 0.95\n",
    "        y_val_pred = (val_proba >= t).astype(int)\n",
    "        f1 = f1_score(y_val, y_val_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t = t\n",
    "\n",
    "    print(f\"[Validation] Best threshold = {best_t:.3f}, F1 = {best_f1:.4f}\")\n",
    "\n",
    "    # 用整個 train 重練\n",
    "    model.fit(X_train[feature_cols], y_train)\n",
    "\n",
    "    # 在 test 上用 best threshold\n",
    "    test_proba = model.predict_proba(X_test[feature_cols])[:, 1]\n",
    "    y_test_pred = (test_proba >= best_t).astype(int)\n",
    "\n",
    "    return y_test_pred, best_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "418ba6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##f1 score 0.38\n",
    "def GBDT_Modeling(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    進階模型版本：\n",
    "    GradientBoosting (sklearn GBDT) + 類別權重 + threshold tuning\n",
    "\n",
    "    步驟：\n",
    "    1. 從 training 中切出 validation\n",
    "    2. 用 GBDT 訓練（對正類給比較大的權重）\n",
    "    3. 在 validation 上掃 threshold → maximize F1\n",
    "    4. 用整個 training 重訓\n",
    "    5. 在 test 上用最佳 threshold 預測\n",
    "    \"\"\"\n",
    "\n",
    "    feature_cols = [c for c in X_train.columns if c not in [\"acct\"]]\n",
    "\n",
    "    # 1. train / val split\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train[feature_cols],\n",
    "        y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_train\n",
    "    )\n",
    "\n",
    "    # 2. 準備 sample_weight 來處理不平衡\n",
    "    #    讓少數正類(1)的權重比較大\n",
    "    pos = (y_tr == 1).sum()\n",
    "    neg = (y_tr == 0).sum()\n",
    "    # 反比於出現頻率\n",
    "    w_pos = neg / (pos + 1e-9)\n",
    "    w_neg = 1.0\n",
    "\n",
    "    sample_weight = np.where(y_tr == 1, w_pos, w_neg)\n",
    "\n",
    "    # 3. 建 GBDT 模型\n",
    "    model = GradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=500,\n",
    "        max_depth=3,\n",
    "        subsample=0.8,\n",
    "        max_features=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_tr, y_tr, sample_weight=sample_weight)\n",
    "\n",
    "    # 4. validation 上掃描 threshold 找最佳 F1\n",
    "    val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    best_t, best_f1 = 0.5, 0.0\n",
    "    for t in np.linspace(0.01, 0.99, 99):\n",
    "        y_pred_t = (val_proba >= t).astype(int)\n",
    "        f1 = f1_score(y_val, y_pred_t)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t = t\n",
    "\n",
    "    print(f\"[Validation] Best threshold = {best_t:.3f}, F1 = {best_f1:.4f}\")\n",
    "\n",
    "    # 5. 用整個 training 重訓\n",
    "    #    重新算一次 sample_weight（用全部 training）\n",
    "    pos_all = (y_train == 1).sum()\n",
    "    neg_all = (y_train == 0).sum()\n",
    "    w_pos_all = neg_all / (pos_all + 1e-9)\n",
    "    w_neg_all = 1.0\n",
    "    sample_weight_all = np.where(y_train == 1, w_pos_all, w_neg_all)\n",
    "\n",
    "    model.fit(X_train[feature_cols], y_train, sample_weight=sample_weight_all)\n",
    "\n",
    "    # 6. 在 test 上用 best threshold 預測\n",
    "    test_proba = model.predict_proba(X_test[feature_cols])[:, 1]\n",
    "    y_test_pred = (test_proba >= best_t).astype(int)\n",
    "\n",
    "    return y_test_pred, best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16fa71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##f1 score 0.42\n",
    "def HGB_Modeling(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    更進階模型：\n",
    "    HistGradientBoostingClassifier + K-fold OOF threshold tuning\n",
    "\n",
    "    流程：\n",
    "    1. 使用 K 折交叉驗證 (StratifiedKFold)，對每一折做訓練與 out-of-fold 預測\n",
    "    2. 收集所有 OOF 機率，掃描 threshold，找整體 F1-score 最高的門檻\n",
    "    3. 用最佳超參數與 sample_weight 在「整個 training」上重訓\n",
    "    4. 對 test 做預測，並用最佳 threshold 轉成 0/1 label\n",
    "    \"\"\"\n",
    "\n",
    "    # 不要把 acct 這種 ID 當特徵\n",
    "    feature_cols = [c for c in X_train.columns if c not in [\"acct\"]]\n",
    "\n",
    "    X = X_train[feature_cols].values\n",
    "    y = y_train.values\n",
    "\n",
    "    # ---------- 1. 準備 K 折 ---------- #\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # 存 out-of-fold 預測機率\n",
    "    oof_proba = np.zeros_like(y, dtype=float)\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y), start=1):\n",
    "        X_tr, X_val = X[tr_idx], X[val_idx]\n",
    "        y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "        # 計算 sample_weight：讓正類(1)權重較大，處理不平衡\n",
    "        pos = (y_tr == 1).sum()\n",
    "        neg = (y_tr == 0).sum()\n",
    "        w_pos = neg / (pos + 1e-9)\n",
    "        w_neg = 1.0\n",
    "        sample_weight = np.where(y_tr == 1, w_pos, w_neg)\n",
    "\n",
    "        model = HistGradientBoostingClassifier(\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            max_iter=400,\n",
    "            max_leaf_nodes=63,\n",
    "            min_samples_leaf=20,\n",
    "            l2_regularization=1.0,\n",
    "            validation_fraction=None,  # 我們自己做 K-fold，不用內建 validation\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        model.fit(X_tr, y_tr, sample_weight=sample_weight)\n",
    "\n",
    "        # 這裡預測 validation fold 機率（out-of-fold）\n",
    "        val_proba = model.predict_proba(X_val)[:, 1]\n",
    "        oof_proba[val_idx] = val_proba\n",
    "\n",
    "        print(f\"[KFold] fold {fold} done.\")\n",
    "\n",
    "    # ---------- 2. 用 OOF 機率找最佳 threshold ---------- #\n",
    "    best_t, best_f1 = 0.5, 0.0\n",
    "    for t in np.linspace(0.01, 0.99, 99):\n",
    "        y_oof_pred = (oof_proba >= t).astype(int)\n",
    "        f1 = f1_score(y, y_oof_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t = t\n",
    "\n",
    "    print(f\"[OOF] Best threshold = {best_t:.3f}, F1 = {best_f1:.4f}\")\n",
    "\n",
    "    # ---------- 3. 用整個 training 重訓最終模型 ---------- #\n",
    "    pos_all = (y == 1).sum()\n",
    "    neg_all = (y == 0).sum()\n",
    "    w_pos_all = neg_all / (pos_all + 1e-9)\n",
    "    w_neg_all = 1.0\n",
    "    sample_weight_all = np.where(y == 1, w_pos_all, w_neg_all)\n",
    "\n",
    "    final_model = HistGradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        max_iter=400,\n",
    "        max_leaf_nodes=63,\n",
    "        min_samples_leaf=20,\n",
    "        l2_regularization=1.0,\n",
    "        validation_fraction=None,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    final_model.fit(X, y, sample_weight=sample_weight_all)\n",
    "\n",
    "    # ---------- 4. 在 test 上用 best_t 預測 ---------- #\n",
    "    X_test_arr = X_test[feature_cols].values\n",
    "    test_proba = final_model.predict_proba(X_test_arr)[:, 1]\n",
    "    y_test_pred = (test_proba >= best_t).astype(int)\n",
    "\n",
    "    return y_test_pred, best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dedbdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score 0.38 \n",
    "# f1\n",
    "def Stacking_Ensemble_Modeling(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    超進階模型：\n",
    "    RandomForest + GBDT + HistGBDT 的 Stacking Ensemble\n",
    "    + Stratified K-Fold OOF\n",
    "    + OOF 上調 threshold maximize F1\n",
    "    \"\"\"\n",
    "\n",
    "    feature_cols = [c for c in X_train.columns if c not in [\"acct\"]]\n",
    "\n",
    "    X = X_train[feature_cols].values\n",
    "    y = y_train.values\n",
    "    X_test_arr = X_test[feature_cols].values\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # OOF 機率（每個模型一個）\n",
    "    oof_rf   = np.zeros(len(y))\n",
    "    oof_gbdt = np.zeros(len(y))\n",
    "    oof_hgb  = np.zeros(len(y))\n",
    "\n",
    "    # test 機率（每 fold 訓練一次，最後取平均）\n",
    "    test_rf   = np.zeros((5, len(X_test_arr)))\n",
    "    test_gbdt = np.zeros((5, len(X_test_arr)))\n",
    "    test_hgb  = np.zeros((5, len(X_test_arr)))\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y), start=1):\n",
    "        X_tr, X_val = X[tr_idx], X[val_idx]\n",
    "        y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "        # --------- 不平衡權重 ---------\n",
    "        pos = (y_tr == 1).sum()\n",
    "        neg = (y_tr == 0).sum()\n",
    "        w_pos = neg / (pos + 1e-9)\n",
    "        w_neg = 1.0\n",
    "        sample_weight = np.where(y_tr == 1, w_pos, w_neg)\n",
    "\n",
    "        # --------- Model 1: RandomForest ---------\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=400,\n",
    "            max_depth=None,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            class_weight=None\n",
    "        )\n",
    "        rf.fit(X_tr, y_tr, sample_weight=sample_weight)\n",
    "        oof_rf[val_idx] = rf.predict_proba(X_val)[:, 1]\n",
    "        test_rf[fold-1] = rf.predict_proba(X_test_arr)[:, 1]\n",
    "\n",
    "        # --------- Model 2: GradientBoosting ---------\n",
    "        gbdt = GradientBoostingClassifier(\n",
    "            learning_rate=0.05,\n",
    "            n_estimators=500,\n",
    "            max_depth=3,\n",
    "            subsample=0.8,\n",
    "            max_features=0.8,\n",
    "            random_state=42\n",
    "        )\n",
    "        gbdt.fit(X_tr, y_tr, sample_weight=sample_weight)\n",
    "        oof_gbdt[val_idx] = gbdt.predict_proba(X_val)[:, 1]\n",
    "        test_gbdt[fold-1] = gbdt.predict_proba(X_test_arr)[:, 1]\n",
    "\n",
    "        # --------- Model 3: HistGradientBoosting ---------\n",
    "        hgb = HistGradientBoostingClassifier(\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            max_iter=400,\n",
    "            max_leaf_nodes=63,\n",
    "            min_samples_leaf=20,\n",
    "            l2_regularization=1.0,\n",
    "            validation_fraction=None,\n",
    "            random_state=42\n",
    "        )\n",
    "        hgb.fit(X_tr, y_tr, sample_weight=sample_weight)\n",
    "        oof_hgb[val_idx] = hgb.predict_proba(X_val)[:, 1]\n",
    "        test_hgb[fold-1] = hgb.predict_proba(X_test_arr)[:, 1]\n",
    "\n",
    "        print(f\"[Stacking] Fold {fold} done.\")\n",
    "\n",
    "    # --------- 第二層資料（OOF 作為新特徵）---------\n",
    "    X_meta = np.column_stack([oof_rf, oof_gbdt, oof_hgb])\n",
    "\n",
    "    # --------- 第二層模型（Logistic Regression）---------\n",
    "    meta_model = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "    meta_model.fit(X_meta, y)\n",
    "\n",
    "    oof_meta_proba = meta_model.predict_proba(X_meta)[:, 1]\n",
    "\n",
    "    # --------- OOF 上找最佳 threshold ---------\n",
    "    best_t, best_f1 = 0.5, 0.0\n",
    "    for t in np.linspace(0.01, 0.99, 99):\n",
    "        y_oof_pred = (oof_meta_proba >= t).astype(int)\n",
    "        f1 = f1_score(y, y_oof_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t = t\n",
    "\n",
    "    print(f\"[OOF-STACK] Best threshold = {best_t:.3f}, F1 = {best_f1:.4f}\")\n",
    "\n",
    "    # --------- 用全訓練資料 + 平均 test 機率 做最終預測 ---------\n",
    "    test_rf_mean   = test_rf.mean(axis=0)\n",
    "    test_gbdt_mean = test_gbdt.mean(axis=0)\n",
    "    test_hgb_mean  = test_hgb.mean(axis=0)\n",
    "\n",
    "    X_test_meta = np.column_stack([\n",
    "        test_rf_mean,\n",
    "        test_gbdt_mean,\n",
    "        test_hgb_mean\n",
    "    ])\n",
    "\n",
    "    test_meta_proba = meta_model.predict_proba(X_test_meta)[:, 1]\n",
    "    y_test_pred = (test_meta_proba >= best_t).astype(int)\n",
    "\n",
    "    return y_test_pred, best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc68b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Finish) Load Dataset.\n",
      "(Finish) PreProcessing.\n",
      "Total accounts (esun only): 317313, positives=1004, negatives=316309, ratio=0.003164\n",
      "(Finish) Train-Test Split. Train=222119, Test=95194\n",
      "[Stacking] Fold 1 done.\n",
      "[Stacking] Fold 2 done.\n",
      "[Stacking] Fold 3 done.\n",
      "[Stacking] Fold 4 done.\n",
      "[Stacking] Fold 5 done.\n",
      "[OOF-STACK] Best threshold = 0.980, F1 = 0.3867\n",
      "\n",
      "=== Evaluation on TEST set ===\n",
      "Best threshold used on test = 0.980\n",
      "Precision: 0.6268656716417911\n",
      "Recall:    0.27906976744186046\n",
      "F1-score:  0.38620689655172413\n",
      "\n",
      "Detailed Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     94893\n",
      "           1       0.63      0.28      0.39       301\n",
      "\n",
      "    accuracy                           1.00     95194\n",
      "   macro avg       0.81      0.64      0.69     95194\n",
      "weighted avg       1.00      1.00      1.00     95194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 資料路徑\n",
    "    dir_path = \"./data/raw\"\n",
    "\n",
    "    # 1. 讀資料\n",
    "    df_txn, df_alert = LoadCSV(dir_path)\n",
    "\n",
    "    # 2. 特徵工程\n",
    "    df_X = PreProcessing(df_txn)\n",
    "\n",
    "    # 3. 切 train/test\n",
    "    X_train, X_test, y_train, y_test = TrainTestSplit(df_X, df_alert)\n",
    "\n",
    "    # 4. 模型訓練 + threshold tuning\n",
    "    y_pred, best_t =  Stacking_Ensemble_Modeling(X_train, y_train, X_test)\n",
    "\n",
    "    # 5. 評估\n",
    "    print(\"\\n=== Evaluation on TEST set ===\")\n",
    "    print(f\"Best threshold used on test = {best_t:.3f}\")\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "    print(\"Recall:   \", recall_score(y_test, y_pred))\n",
    "    print(\"F1-score: \", f1_score(y_test, y_pred))\n",
    "    print(\"\\nDetailed Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
